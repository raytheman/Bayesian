{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Clean] The Evolutionary Origin of Bayesian-like Behavior and Finite Memory",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raytheman/Bayesian/blob/main/%5BClean%5D_The_Evolutionary_Origin_of_Bayesian_like_Behavior_and_Finite_Memory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSX2VsG7mAWP"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq4CjW7q_v_J"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "from scipy.stats import binom, pearsonr\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "import multiprocessing as mp\n",
        "from google.colab import files, drive\n",
        "from statsmodels.tsa.arima_process import arma_generate_sample\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-czLAlJ4cLi_"
      },
      "source": [
        "EPSILON = 1E-8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80JKtGbVmDGR"
      },
      "source": [
        "#Sampling with Limited Information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haYvzDQrAIpd"
      },
      "source": [
        "# Probability of State Given Sample\n",
        "\n",
        "def binon_right_prob(\n",
        "    k, p\n",
        "):\n",
        "  '''\n",
        "  k: number of sample\n",
        "  p: probability that each sample is correct\n",
        "  '''\n",
        "  if not isinstance(k, int):\n",
        "    print('input k must be integer')\n",
        "    assert(False)\n",
        "  prob = 1 - binom.cdf(k/2, k, p)\n",
        "  if k % 2 == 0:\n",
        "    prob += binom.pmf(k/2, k, p) / 2\n",
        "  return prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLxnYo3EF3FA"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(5,4))\n",
        "k = np.arange(1,10)\n",
        "for q in [0.9, 0.8, 0.7, 0.6]:\n",
        "  plt.plot(\n",
        "      k, [binon_right_prob(int(x), q) for x in k],\n",
        "      'o-',\n",
        "      label='q=' + str(q)\n",
        "  )\n",
        "plt.xlabel('Number of samples')\n",
        "plt.ylabel('Probability to choose the right state')\n",
        "plt.ylim(0.53, 1.02)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "fig.savefig('binomial_cdf.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTt1OCGFEnHS"
      },
      "source": [
        "#Optimal Growth Rate\n",
        "\n",
        "def growth_rate_with_opt_behavior(\n",
        "    mode,\n",
        "    fitness=3,\n",
        "    weather_prob=0.8,\n",
        "    regime_prob=0.5,\n",
        "    num_sample=None,\n",
        "    sample_correct_prob=None,\n",
        "    cost_factor=None,\n",
        "):\n",
        "  '''\n",
        "  mode: version of the model: {no sample, infinite sample, limited sample}\n",
        "  fitness: number of offspring when env is in favor\n",
        "  weather_prob: probability of sunny weather in summer, and rainy weather in winter\n",
        "  regime_prob: probability of summer\n",
        "  num_sample: number of samples (required when mode=='limited sample'),\n",
        "  sample_correct_prob: probability that each sample is correct (required when mode=='limited sample'),\n",
        "  cost_factor: cost factor for each sample (required when mode=='limited sample')\n",
        "  '''\n",
        "  p = weather_prob\n",
        "  if mode == 'no sample':\n",
        "    growth = regime_prob * math.log(regime_prob * fitness) + (1-regime_prob) * math.log((1-regime_prob) * fitness)\n",
        "  elif mode == 'infinite sample':\n",
        "    growth = p * math.log(p * fitness) + (1 - p) * math.log((1 - p) * fitness)\n",
        "  elif mode == 'limited sample':\n",
        "    if num_sample is None or sample_correct_prob is None or cost_factor is None:\n",
        "      print('some input is None when mode is limited sample')\n",
        "      assert False\n",
        "    q = binon_right_prob(num_sample, sample_correct_prob)\n",
        "    f = (1 - p) * (1 - q) + p * q\n",
        "    growth = (\n",
        "        p * (q * math.log(f * fitness) + (1 - q) * math.log((1 - f) * fitness))\n",
        "        + (1 - p) * (q * math.log((1 - f) * fitness)\n",
        "            + (1 - q) * math.log(f * fitness))\n",
        "        - math.log(1 + num_sample * cost_factor))\n",
        "\n",
        "  else:\n",
        "    print('mode not right')\n",
        "    assert False\n",
        "  \n",
        "  return growth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAuaDZoEm4Pm"
      },
      "source": [
        "# Optimal number of samples\n",
        "\n",
        "def optimal_samples(\n",
        "    sample_correct_prob,\n",
        "    cost_factor,\n",
        "    fitness=3,\n",
        "    weather_prob=0.8,\n",
        "    regime_prob=0.5,\n",
        "    max_samples=1000,\n",
        "    verbose=False,\n",
        "):\n",
        "  '''\n",
        "  sample_correct_prob: probability that each sample is correct (required when mode=='limited sample'),\n",
        "  cost_factor: cost factor for each sample (required when mode=='limited sample')\n",
        "  fitness: number of offspring when env is in favor\n",
        "  weather_prob: probability of sunny weather in summer, and rainy weather in winter\n",
        "  regime_prob: probability of summer\n",
        "  '''\n",
        "  results = {}\n",
        "  optimal_sample = -1\n",
        "  max_alpha = -9999\n",
        "  for num_sample in np.arange(0, max_samples):\n",
        "    alpha = growth_rate_with_opt_behavior(\n",
        "        mode='limited sample',\n",
        "        num_sample=int(num_sample),\n",
        "        sample_correct_prob=sample_correct_prob,\n",
        "        cost_factor=cost_factor,\n",
        "    )\n",
        "    results[num_sample] = alpha\n",
        "    if alpha > max_alpha:\n",
        "      max_alpha = alpha\n",
        "      optimal_sample = num_sample\n",
        "    if verbose and num_sample <= 10:\n",
        "      print('k=' + str(num_sample) + ' alpha=' + str(alpha))\n",
        "  return optimal_sample, results\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrRxkHKKLmEC"
      },
      "source": [
        "opt_sample, results = optimal_samples(sample_correct_prob=0.8, cost_factor=0.02, verbose=True)\n",
        "print(opt_sample)\n",
        "\n",
        "x = [0] + list(np.arange(1,12,2))\n",
        "y = [results[xval] for xval in x]\n",
        "fig, ax = plt.subplots(figsize=(5,4))\n",
        "plt.plot(\n",
        "    x, y,\n",
        "    'ko-',\n",
        "    label='Limited Sample w/ Cost'\n",
        ")\n",
        "plt.plot(\n",
        "    [0, 12],\n",
        "    [alpha_infinite_sample, alpha_infinite_sample],\n",
        "    'k--',\n",
        "    label='Infinite Sample w/o Cost'\n",
        ")\n",
        "plt.plot(\n",
        "    [0, 12],\n",
        "    [alpha_no_sample, alpha_no_sample],\n",
        "    'k-.',\n",
        "    label='No Sample'\n",
        ")\n",
        "plt.scatter(\n",
        "    [opt_sample],\n",
        "    [results[opt_sample]],\n",
        "    s=200,\n",
        "    color='k',\n",
        ")\n",
        "plt.xlabel('Number of samples')\n",
        "plt.ylabel('Growth rate')\n",
        "plt.ylim(0.37, 0.62)\n",
        "plt.legend(loc='center right')\n",
        "plt.show()\n",
        "fig.savefig('optimal_sample.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8v7t4JRSllF"
      },
      "source": [
        "#Optimal number of samples as cost change\n",
        "\n",
        "cost_vec = [0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.5, 1]\n",
        "opt_sample_vec = []\n",
        "for cost in cost_vec:\n",
        "  opt_sample, results = optimal_samples(sample_correct_prob=0.8, cost_factor=cost)\n",
        "  opt_sample_vec.append(opt_sample)\n",
        "  print('cost=' + str(cost) + ' opt_sample=' + str(opt_sample))\n",
        "  \n",
        "  \n",
        "fig, ax = plt.subplots(figsize=(5,4))\n",
        "plt.plot(\n",
        "    np.log10(np.array(cost_vec)), opt_sample_vec,\n",
        "    'ko-',\n",
        ")\n",
        "plt.xlabel('Log10(cost magnitude)')\n",
        "plt.ylabel('Optimal samples')\n",
        "# plt.ylim(-1, 16)\n",
        "fig.gca().yaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "plt.show()\n",
        "fig.savefig('optimal_sample_with_cost.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOYVSA1fpP0X"
      },
      "source": [
        "# Optimal number of samples as data information increases\n",
        "\n",
        "probs = np.arange(0.5, 1.01, 0.025)\n",
        "opt_sample_vec = []\n",
        "for sample_correct_prob in probs:\n",
        "  opt_sample, results = optimal_samples(sample_correct_prob=round(sample_correct_prob, 5), cost_factor=0.005)\n",
        "  opt_sample_vec.append(opt_sample)\n",
        "  print('sample_correct_prob=' + str(round(sample_correct_prob, 3)) + ' opt_sample=' + str(opt_sample))\n",
        "  \n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5,4))\n",
        "plt.plot(\n",
        "    probs, opt_sample_vec,\n",
        "    'ko-',\n",
        ")\n",
        "plt.xlabel('Probability that each sample is correct (q)')\n",
        "plt.ylabel('Optimal samples')\n",
        "# plt.ylim(-1, 16)\n",
        "fig.gca().yaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "plt.show()\n",
        "fig.savefig('optimal_sample_with_information.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S49dJ5OyJawZ"
      },
      "source": [
        "%%time\n",
        "log_cost_vec = np.arange(-2.5, -0.49, 0.1)\n",
        "probs = np.arange(0.5, 1.01, 0.025)\n",
        "\n",
        "optimal_results_df = pd.DataFrame()\n",
        "\n",
        "for cost in log_cost_vec:\n",
        "  print('log cost=' + str(cost))\n",
        "  for sample_correct_prob in probs:\n",
        "    opt_sample, _ = optimal_samples(\n",
        "        sample_correct_prob=round(sample_correct_prob, 5),\n",
        "        cost_factor=math.pow(10, cost),\n",
        "        max_samples=100)\n",
        "    optimal_values = {'optimal_sample': opt_sample}\n",
        "    optimal_values['sample_correct_prob'] = sample_correct_prob\n",
        "    optimal_values['log_cost'] = cost\n",
        "    optimal_results_df = optimal_results_df.append(optimal_values, ignore_index=True)\n",
        "\n",
        "eta_dim = len(optimal_results_df['log_cost'].unique())\n",
        "q_dim = len(optimal_results_df['sample_correct_prob'].unique())\n",
        "\n",
        "df_plot = np.array(optimal_results_df['optimal_sample']).reshape(eta_dim, q_dim)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "plt.imshow(df_plot, cmap='jet',\n",
        "           interpolation='bicubic',\n",
        "           )\n",
        "ax.set_xlabel('Probability that each sample is correct ($q$)')\n",
        "ax.set_ylabel('Log of cost magnitude ($\\log(\\eta)$)')\n",
        "ax.set_yticks(np.arange(eta_dim)[::4])\n",
        "ax.set_yticklabels(optimal_results_df['log_cost'].unique()[::4].round(2))\n",
        "ax.set_xticks(np.arange(q_dim)[::4])\n",
        "ax.set_xticklabels(optimal_results_df['sample_correct_prob'].unique()[::4].round(2))\n",
        "cbar = plt.colorbar()\n",
        "cbar.set_label('Optimal Number of Samples (m*)')\n",
        "cbar.set_ticks(np.arange(df_plot.min(), df_plot.max(), 4))\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "plt.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afCUNJlBc-lp"
      },
      "source": [
        "# Finite Memory in Nonstationary Env"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj9zoHaec-S9"
      },
      "source": [
        "def ar_k(\n",
        "    k, coefficient, noise_sigma, n_sample,\n",
        "):\n",
        "  '''\n",
        "  p_t = c / k * (p_{t-1} + ... + p_{t-k}) + e_t\n",
        "  k: order of AR\n",
        "  coefficient: coefficient for lag terms\n",
        "  noise_sigma: standard deviation of the white noise\n",
        "  n_sample: number of samples to generate\n",
        "  '''\n",
        "  warmup = np.random.normal(0, noise_sigma, k)\n",
        "  series = list(warmup)\n",
        "  errors = np.random.normal(0, noise_sigma, size=n_sample)\n",
        "  for i in range(n_sample):\n",
        "    next_value = coefficient * np.mean(series[-k:]) + errors[i]\n",
        "    series.append(next_value)\n",
        "  return np.array(series[k:])\n",
        "\n",
        "def logistic(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def srw(n_sample):\n",
        "  '''\n",
        "  n_sample: number of samples to generate\n",
        "  '''\n",
        "  bernoulli = np.random.binomial(1, 0.5, n_sample)\n",
        "  steps = bernoulli * 2 -1\n",
        "  return steps.cumsum()\n",
        "\n",
        "def ar_plus_srw(\n",
        "    k, coefficient, noise_sigma, n_sample, weight_srw,\n",
        "):\n",
        "  '''\n",
        "  p_t = c / k * (p_{t-1} + ... + p_{t-k}) + e_t\n",
        "  k: order of AR\n",
        "  coefficient: coefficient for lag terms\n",
        "  noise_sigma: standard deviation of the white noise\n",
        "  n_sample: number of samples to generate\n",
        "  weight_srw:\n",
        "  '''\n",
        "  ar_series = np.array(ar_k(\n",
        "    k, coefficient, noise_sigma, n_sample,))\n",
        "  srw_series = np.array(srw(n_sample))\n",
        "  # print(ar_series)\n",
        "  # print(srw_series)\n",
        "  return (1 - weight_srw) + ar_series + weight_srw * srw_series\n",
        "\n",
        "def explore_combined(\n",
        "    k, coefficient, noise_sigma, n_sample, weight_srw, autocorr_lag=100,\n",
        "    show_plots=True,):\n",
        "  ts_combined = ar_plus_srw(\n",
        "      k=k, coefficient=coefficient, noise_sigma=noise_sigma, n_sample=n_sample, weight_srw=weight_srw,\n",
        "  )\n",
        "  if show_plots:\n",
        "    plt.plot(np.arange(len(ts_combined)), ts_combined)\n",
        "    plt.show()\n",
        "    plt.plot(np.arange(len(ts_combined)), logistic(ts_combined))\n",
        "    plt.show()\n",
        "\n",
        "  if show_plots:\n",
        "    auto_corr = autocorr(ts_combined, lag=autocorr_lag)\n",
        "    auto_corr_pt = autocorr(logistic(ts_combined), lag=autocorr_lag)\n",
        "    plt.plot(np.arange(len(auto_corr)), auto_corr,\n",
        "            label='s_t', alpha=0.6)\n",
        "    plt.plot(np.arange(len(auto_corr_pt)), auto_corr_pt,\n",
        "            label='p_t', alpha=0.6)\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "\n",
        "  return ts_combined"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVizXMmQdeRX"
      },
      "source": [
        "def compare_paths(\n",
        "    k, coefficient, noise_sigma, n_sample, weight_srw):\n",
        "  fig, ax = plt.subplots(figsize=(4.4, 3.3))\n",
        "  for i in range(len(k)):\n",
        "    ts = ar_plus_srw(\n",
        "        k=k[i], coefficient=coefficient[i], noise_sigma=noise_sigma[i],\n",
        "        n_sample=n_sample[i], weight_srw=weight_srw[i],\n",
        "    )\n",
        "    plt.plot(np.arange(len(ts)), logistic(ts),\n",
        "             alpha=0.7, \n",
        "             label='$\\lambda$=' + str(weight_srw[i]))\n",
        "  plt.xlabel('Generation (t)')\n",
        "  plt.ylabel('Probability of Sunny Day ($p_t$)')\n",
        "  plt.legend(loc='best')\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "  return 0\n",
        "\n",
        "compare_paths(\n",
        "    k=[10, 10],\n",
        "    coefficient=[0.9, 0.9],\n",
        "    noise_sigma=[1, 1],\n",
        "    n_sample=[300, 300],\n",
        "    weight_srw=[0.1, 0.9])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5jGM9Lndm5s"
      },
      "source": [
        "#Population growth\n",
        "\n",
        "def fitness_prob_matching(f, p, fitness=3):\n",
        "  '''\n",
        "  f: behavior\n",
        "  p: environmental probability\n",
        "  '''\n",
        "  return np.where(\n",
        "      p > 1 - EPSILON,\n",
        "      np.log(f) + np.log(fitness),\n",
        "      np.where(\n",
        "          p < EPSILON,\n",
        "          np.log(1 - f) + np.log(fitness),\n",
        "          p * np.log(f) + (1 - p) * np.log(1 - f) + np.log(fitness)\n",
        "      ))\n",
        "\n",
        "def evolution(states, fitness, max_memory):\n",
        "  sim_results = pd.DataFrame({\n",
        "      't': np.arange(len(states)),\n",
        "      's_t': states,\n",
        "      'p_t': logistic(states),\n",
        "      })\n",
        "\n",
        "  for memory in np.arange(1, max_memory+1):\n",
        "    sim_results['S_t_ma_' + str(memory)] = sim_results.shift(1)['s_t'].rolling(window=memory).mean()\n",
        "    sim_results['f_t_mem_' + str(memory)] = logistic(sim_results['S_t_ma_' + str(memory)])\n",
        "\n",
        "  sim_results['fitness_t_oracle'] = fitness_prob_matching(\n",
        "      f=sim_results['p_t'],\n",
        "      p=sim_results['p_t'],\n",
        "      fitness=fitness)\n",
        "\n",
        "  for constant_f in np.arange(0, 1.1, 0.1):\n",
        "    sim_results['fitness_t_const_' + str(round(constant_f, 1))] = fitness_prob_matching(\n",
        "        f=round(constant_f, 1),\n",
        "        p=sim_results['p_t'],\n",
        "        fitness=fitness)\n",
        "\n",
        "  for memory in np.arange(1, max_memory+1):\n",
        "    sim_results['fitness_t_mem_' + str(memory)] = fitness_prob_matching(\n",
        "        f=sim_results['f_t_mem_' + str(memory)],\n",
        "        p=sim_results['p_t'],\n",
        "        fitness=fitness)\n",
        "\n",
        "  growth_rates = sim_results[[name for name in sim_results.columns if 'fitness' in name]].mean()\n",
        "  return growth_rates, sim_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Lj08QVhdszm"
      },
      "source": [
        "#Optimal behavior and memory\n",
        "\n",
        "def optimal_behavior(growth_rates):\n",
        "  mu_oracle = growth_rates['fitness_t_oracle']\n",
        "  f_const = growth_rates[[name for name in growth_rates.index if 'const' in name]].idxmax()\n",
        "  mu_const = growth_rates[[name for name in growth_rates.index if 'const' in name]].max()\n",
        "  f_mem = growth_rates[[name for name in growth_rates.index if 'mem' in name]].idxmax()\n",
        "  mu_mem = growth_rates[[name for name in growth_rates.index if 'mem' in name]].max()\n",
        "  return {\n",
        "      'mu_oracle': mu_oracle,\n",
        "      'mu_const': mu_const,\n",
        "      'mu_mem': mu_mem,\n",
        "      'f_star_const': float(f_const[len('fitness_t_const_'):]),\n",
        "      'mem_star': int(f_mem[len('fitness_t_mem_'):]),\n",
        "  }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1NNAUU5dzyy"
      },
      "source": [
        "##Dependence on Markov order and non-stationarity\n",
        "\n",
        "%%time\n",
        "\n",
        "def OneSim(lag_vec, weight_srw_vec, n_gen, sim_count, seed):\n",
        "  print('-----Running Sim #' + str(sim_count) + ' with seed=' + str(seed))\n",
        "  np.random.seed(seed)\n",
        "  optimal_results_df = pd.DataFrame()\n",
        "  for lag in lag_vec:\n",
        "    for weight_srw in weight_srw_vec:\n",
        "      states = explore_combined(\n",
        "          k=lag,\n",
        "          coefficient=0.9,\n",
        "          noise_sigma=1,\n",
        "          n_sample=n_gen,\n",
        "          weight_srw=weight_srw,\n",
        "          show_plots=False)\n",
        "      growth_rates, _ = evolution(states, fitness=3, max_memory=30)\n",
        "      optimal_values = optimal_behavior(growth_rates)\n",
        "      optimal_values['sim'] = sim_count\n",
        "      optimal_values['AR_lag'] = lag\n",
        "      optimal_values['weight_srw'] = weight_srw\n",
        "      optimal_results_df = optimal_results_df.append(optimal_values, ignore_index=True)\n",
        "  return optimal_results_df\n",
        "\n",
        "def SimForOptMemory(lag_vec, weight_srw_vec, n_gen, n_sim = 30, n_workers = 4, max_seed=99999999):\n",
        "  pool = mp.Pool(processes = n_workers)\n",
        "  seeds = np.random.randint(max_seed, size=n_sim, dtype=np.int32)\n",
        "  results = [pool.apply(OneSim, args=(lag_vec, weight_srw_vec, n_gen, k, seeds[k])) for k in range(n_sim)]\n",
        "  # results is a list with length=n_sim, each element is the returned dataframe from OneSim\n",
        "  return pd.concat(results)\n",
        "\n",
        "\n",
        "lag_vec = np.arange(1, 31, 1)\n",
        "weight_srw_vec = np.arange(0.025, 1.0, 0.025)\n",
        "n_gen = 30000\n",
        "n_sim = 50\n",
        "\n",
        "sim_results = SimForOptMemory(lag_vec, weight_srw_vec, n_gen, n_sim = n_sim, n_workers = 2, max_seed=99999999)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGZt4pUed13C"
      },
      "source": [
        "optimal_values_median = sim_results.groupby(['AR_lag', 'weight_srw'])[['mem_star']].median()\n",
        "\n",
        "ar_dim = len(optimal_values_median.reset_index()['AR_lag'].unique())\n",
        "weight_dim = len(optimal_values_median.reset_index()['weight_srw'].unique())\n",
        "\n",
        "df_plot = np.array(optimal_values_median['mem_star']).reshape(ar_dim, weight_dim)\n",
        "\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "fig, ax = plt.subplots()\n",
        "im = plt.imshow(df_plot, cmap='jet',\n",
        "           interpolation='bicubic',\n",
        "           aspect=1.2,\n",
        "           )\n",
        "ax.set_xlabel('SRW weight ($\\lambda$)')\n",
        "ax.set_ylabel('AR lag ($k$)')\n",
        "\n",
        "ax.set_xticks(np.arange(weight_dim)[3::4])\n",
        "ax.set_xticklabels(optimal_values_median.reset_index()['weight_srw'].unique().round(2)[3::4])\n",
        "ax.set_xlim(0, weight_dim-1)\n",
        "\n",
        "ax.set_yticks(np.arange(ar_dim)[::4])\n",
        "ax.set_yticklabels(optimal_values_median.reset_index()['AR_lag'].unique().astype(int)[::4])\n",
        "ax.set_ylim(ar_dim-1, 0)\n",
        "\n",
        "divider = make_axes_locatable(ax)\n",
        "cax = divider.append_axes(\"right\", size=\"3.5%\", pad=-0.15)\n",
        "cbar = plt.colorbar(im, cax=cax)\n",
        "cbar.set_label('Optimal Memory (m*)')\n",
        "cbar.set_ticks(np.arange(df_plot.min(), df_plot.max(), 4))\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}